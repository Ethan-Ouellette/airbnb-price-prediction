{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a5d5e83-f6aa-401f-8d19-b58017e07e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b54de9a7-8f4e-44a2-9e11-901fdfa0885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datas/df_1122.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb483fdb-cf9d-4b2e-8caf-8b5d032fc398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7fe34da-d750-4bc8-847d-b511088cbbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95803a7b-410f-49f2-8a29-88d70add8263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethan/miniconda3/envs/cs671/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">68,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m68,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,361</span> (310.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m79,361\u001b[0m (310.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">79,361</span> (310.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m79,361\u001b[0m (310.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the neural network architecture\n",
    "def build_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))  # Output layer for regression\n",
    "    return model\n",
    "\n",
    "# Get the number of input features\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "\n",
    "# Build the model\n",
    "model = build_model(input_dim)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mean_squared_error']\n",
    ")\n",
    "\n",
    "# Display the model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2380dfec-1302-47a7-a49e-3618f1796a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "314/314 - 1s - 4ms/step - loss: 1.9719 - mean_squared_error: 1.9719 - val_loss: 1.0813 - val_mean_squared_error: 1.0813\n",
      "Epoch 2/1000\n",
      "314/314 - 1s - 2ms/step - loss: 1.1648 - mean_squared_error: 1.1648 - val_loss: 1.1072 - val_mean_squared_error: 1.1072\n",
      "Epoch 3/1000\n",
      "314/314 - 1s - 2ms/step - loss: 1.0292 - mean_squared_error: 1.0292 - val_loss: 1.0433 - val_mean_squared_error: 1.0433\n",
      "Epoch 4/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.9045 - mean_squared_error: 0.9045 - val_loss: 0.9772 - val_mean_squared_error: 0.9772\n",
      "Epoch 5/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.8424 - mean_squared_error: 0.8424 - val_loss: 0.9297 - val_mean_squared_error: 0.9297\n",
      "Epoch 6/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.8109 - mean_squared_error: 0.8109 - val_loss: 0.8697 - val_mean_squared_error: 0.8697\n",
      "Epoch 7/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.7584 - mean_squared_error: 0.7584 - val_loss: 1.0142 - val_mean_squared_error: 1.0142\n",
      "Epoch 8/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.7106 - mean_squared_error: 0.7106 - val_loss: 0.8719 - val_mean_squared_error: 0.8719\n",
      "Epoch 9/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.6964 - mean_squared_error: 0.6964 - val_loss: 0.8808 - val_mean_squared_error: 0.8808\n",
      "Epoch 10/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.6706 - mean_squared_error: 0.6706 - val_loss: 0.9311 - val_mean_squared_error: 0.9311\n",
      "Epoch 11/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.6496 - mean_squared_error: 0.6496 - val_loss: 0.9231 - val_mean_squared_error: 0.9231\n",
      "Epoch 12/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.6289 - mean_squared_error: 0.6289 - val_loss: 0.9012 - val_mean_squared_error: 0.9012\n",
      "Epoch 13/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.6020 - mean_squared_error: 0.6020 - val_loss: 0.8296 - val_mean_squared_error: 0.8296\n",
      "Epoch 14/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.5859 - mean_squared_error: 0.5859 - val_loss: 0.8990 - val_mean_squared_error: 0.8990\n",
      "Epoch 15/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.5762 - mean_squared_error: 0.5762 - val_loss: 0.8389 - val_mean_squared_error: 0.8389\n",
      "Epoch 16/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.5473 - mean_squared_error: 0.5473 - val_loss: 0.8363 - val_mean_squared_error: 0.8363\n",
      "Epoch 17/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.5407 - mean_squared_error: 0.5407 - val_loss: 0.8003 - val_mean_squared_error: 0.8003\n",
      "Epoch 18/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.5172 - mean_squared_error: 0.5172 - val_loss: 0.8192 - val_mean_squared_error: 0.8192\n",
      "Epoch 19/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.5079 - mean_squared_error: 0.5079 - val_loss: 0.8025 - val_mean_squared_error: 0.8025\n",
      "Epoch 20/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.4918 - mean_squared_error: 0.4918 - val_loss: 0.8664 - val_mean_squared_error: 0.8664\n",
      "Epoch 21/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.4807 - mean_squared_error: 0.4807 - val_loss: 0.8210 - val_mean_squared_error: 0.8210\n",
      "Epoch 22/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.4764 - mean_squared_error: 0.4764 - val_loss: 0.8066 - val_mean_squared_error: 0.8066\n",
      "Epoch 23/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.4572 - mean_squared_error: 0.4572 - val_loss: 0.8171 - val_mean_squared_error: 0.8171\n",
      "Epoch 24/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.4437 - mean_squared_error: 0.4437 - val_loss: 0.8421 - val_mean_squared_error: 0.8421\n",
      "Epoch 25/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.4425 - mean_squared_error: 0.4425 - val_loss: 0.8060 - val_mean_squared_error: 0.8060\n",
      "Epoch 26/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.4301 - mean_squared_error: 0.4301 - val_loss: 0.7952 - val_mean_squared_error: 0.7952\n",
      "Epoch 27/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.4331 - mean_squared_error: 0.4331 - val_loss: 0.7863 - val_mean_squared_error: 0.7863\n",
      "Epoch 28/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.4211 - mean_squared_error: 0.4211 - val_loss: 0.7462 - val_mean_squared_error: 0.7462\n",
      "Epoch 29/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.4190 - mean_squared_error: 0.4190 - val_loss: 0.8493 - val_mean_squared_error: 0.8493\n",
      "Epoch 30/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.4107 - mean_squared_error: 0.4107 - val_loss: 0.7780 - val_mean_squared_error: 0.7780\n",
      "Epoch 31/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.3971 - mean_squared_error: 0.3971 - val_loss: 0.7861 - val_mean_squared_error: 0.7861\n",
      "Epoch 32/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.3761 - mean_squared_error: 0.3761 - val_loss: 0.7789 - val_mean_squared_error: 0.7789\n",
      "Epoch 33/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.3948 - mean_squared_error: 0.3948 - val_loss: 0.7863 - val_mean_squared_error: 0.7863\n",
      "Epoch 34/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.3809 - mean_squared_error: 0.3809 - val_loss: 0.7537 - val_mean_squared_error: 0.7537\n",
      "Epoch 35/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.3785 - mean_squared_error: 0.3785 - val_loss: 0.7742 - val_mean_squared_error: 0.7742\n",
      "Epoch 36/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.3685 - mean_squared_error: 0.3685 - val_loss: 0.7827 - val_mean_squared_error: 0.7827\n",
      "Epoch 37/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.3708 - mean_squared_error: 0.3708 - val_loss: 0.7831 - val_mean_squared_error: 0.7831\n",
      "Epoch 38/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.3556 - mean_squared_error: 0.3556 - val_loss: 0.7770 - val_mean_squared_error: 0.7770\n",
      "Epoch 39/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.3516 - mean_squared_error: 0.3516 - val_loss: 0.7649 - val_mean_squared_error: 0.7649\n",
      "Epoch 40/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.3432 - mean_squared_error: 0.3432 - val_loss: 0.7388 - val_mean_squared_error: 0.7388\n",
      "Epoch 41/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.3385 - mean_squared_error: 0.3385 - val_loss: 0.8159 - val_mean_squared_error: 0.8159\n",
      "Epoch 42/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.3348 - mean_squared_error: 0.3348 - val_loss: 0.7763 - val_mean_squared_error: 0.7763\n",
      "Epoch 43/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.3312 - mean_squared_error: 0.3312 - val_loss: 0.7762 - val_mean_squared_error: 0.7762\n",
      "Epoch 44/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.3152 - mean_squared_error: 0.3152 - val_loss: 0.7454 - val_mean_squared_error: 0.7454\n",
      "Epoch 45/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.3210 - mean_squared_error: 0.3210 - val_loss: 0.7236 - val_mean_squared_error: 0.7236\n",
      "Epoch 46/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.3182 - mean_squared_error: 0.3182 - val_loss: 0.7697 - val_mean_squared_error: 0.7697\n",
      "Epoch 47/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.3044 - mean_squared_error: 0.3044 - val_loss: 0.7253 - val_mean_squared_error: 0.7253\n",
      "Epoch 48/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.3105 - mean_squared_error: 0.3105 - val_loss: 0.7575 - val_mean_squared_error: 0.7575\n",
      "Epoch 49/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.3008 - mean_squared_error: 0.3008 - val_loss: 0.7473 - val_mean_squared_error: 0.7473\n",
      "Epoch 50/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2964 - mean_squared_error: 0.2964 - val_loss: 0.7232 - val_mean_squared_error: 0.7232\n",
      "Epoch 51/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2970 - mean_squared_error: 0.2970 - val_loss: 0.7358 - val_mean_squared_error: 0.7358\n",
      "Epoch 52/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2964 - mean_squared_error: 0.2964 - val_loss: 0.7322 - val_mean_squared_error: 0.7322\n",
      "Epoch 53/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2921 - mean_squared_error: 0.2921 - val_loss: 0.7488 - val_mean_squared_error: 0.7488\n",
      "Epoch 54/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2761 - mean_squared_error: 0.2761 - val_loss: 0.7310 - val_mean_squared_error: 0.7310\n",
      "Epoch 55/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2800 - mean_squared_error: 0.2800 - val_loss: 0.7142 - val_mean_squared_error: 0.7142\n",
      "Epoch 56/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2768 - mean_squared_error: 0.2768 - val_loss: 0.7315 - val_mean_squared_error: 0.7315\n",
      "Epoch 57/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2791 - mean_squared_error: 0.2791 - val_loss: 0.7469 - val_mean_squared_error: 0.7469\n",
      "Epoch 58/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2755 - mean_squared_error: 0.2755 - val_loss: 0.7085 - val_mean_squared_error: 0.7085\n",
      "Epoch 59/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2748 - mean_squared_error: 0.2748 - val_loss: 0.7282 - val_mean_squared_error: 0.7282\n",
      "Epoch 60/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2683 - mean_squared_error: 0.2683 - val_loss: 0.6987 - val_mean_squared_error: 0.6987\n",
      "Epoch 61/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2594 - mean_squared_error: 0.2594 - val_loss: 0.7447 - val_mean_squared_error: 0.7447\n",
      "Epoch 62/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2636 - mean_squared_error: 0.2636 - val_loss: 0.7319 - val_mean_squared_error: 0.7319\n",
      "Epoch 63/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2666 - mean_squared_error: 0.2666 - val_loss: 0.7278 - val_mean_squared_error: 0.7278\n",
      "Epoch 64/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2521 - mean_squared_error: 0.2521 - val_loss: 0.7270 - val_mean_squared_error: 0.7270\n",
      "Epoch 65/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2451 - mean_squared_error: 0.2451 - val_loss: 0.7350 - val_mean_squared_error: 0.7350\n",
      "Epoch 66/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2499 - mean_squared_error: 0.2499 - val_loss: 0.7316 - val_mean_squared_error: 0.7316\n",
      "Epoch 67/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2554 - mean_squared_error: 0.2554 - val_loss: 0.7272 - val_mean_squared_error: 0.7272\n",
      "Epoch 68/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2471 - mean_squared_error: 0.2471 - val_loss: 0.7347 - val_mean_squared_error: 0.7347\n",
      "Epoch 69/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2452 - mean_squared_error: 0.2452 - val_loss: 0.7454 - val_mean_squared_error: 0.7454\n",
      "Epoch 70/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2414 - mean_squared_error: 0.2414 - val_loss: 0.7254 - val_mean_squared_error: 0.7254\n",
      "Epoch 71/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2425 - mean_squared_error: 0.2425 - val_loss: 0.7565 - val_mean_squared_error: 0.7565\n",
      "Epoch 72/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2424 - mean_squared_error: 0.2424 - val_loss: 0.7383 - val_mean_squared_error: 0.7383\n",
      "Epoch 73/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2406 - mean_squared_error: 0.2406 - val_loss: 0.7274 - val_mean_squared_error: 0.7274\n",
      "Epoch 74/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2373 - mean_squared_error: 0.2373 - val_loss: 0.7209 - val_mean_squared_error: 0.7209\n",
      "Epoch 75/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2285 - mean_squared_error: 0.2285 - val_loss: 0.7116 - val_mean_squared_error: 0.7116\n",
      "Epoch 76/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2273 - mean_squared_error: 0.2273 - val_loss: 0.7334 - val_mean_squared_error: 0.7334\n",
      "Epoch 77/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2391 - mean_squared_error: 0.2391 - val_loss: 0.7172 - val_mean_squared_error: 0.7172\n",
      "Epoch 78/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2295 - mean_squared_error: 0.2295 - val_loss: 0.7427 - val_mean_squared_error: 0.7427\n",
      "Epoch 79/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2239 - mean_squared_error: 0.2239 - val_loss: 0.7380 - val_mean_squared_error: 0.7380\n",
      "Epoch 80/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2264 - mean_squared_error: 0.2264 - val_loss: 0.7288 - val_mean_squared_error: 0.7288\n",
      "Epoch 81/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2273 - mean_squared_error: 0.2273 - val_loss: 0.7226 - val_mean_squared_error: 0.7226\n",
      "Epoch 82/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2159 - mean_squared_error: 0.2159 - val_loss: 0.7622 - val_mean_squared_error: 0.7622\n",
      "Epoch 83/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.2221 - mean_squared_error: 0.2221 - val_loss: 0.7306 - val_mean_squared_error: 0.7306\n",
      "Epoch 84/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2148 - mean_squared_error: 0.2148 - val_loss: 0.7306 - val_mean_squared_error: 0.7306\n",
      "Epoch 85/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2165 - mean_squared_error: 0.2165 - val_loss: 0.7274 - val_mean_squared_error: 0.7274\n",
      "Epoch 86/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2189 - mean_squared_error: 0.2189 - val_loss: 0.7219 - val_mean_squared_error: 0.7219\n",
      "Epoch 87/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2122 - mean_squared_error: 0.2122 - val_loss: 0.7345 - val_mean_squared_error: 0.7345\n",
      "Epoch 88/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.2142 - mean_squared_error: 0.2142 - val_loss: 0.7189 - val_mean_squared_error: 0.7189\n",
      "Epoch 89/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.2163 - mean_squared_error: 0.2163 - val_loss: 0.7193 - val_mean_squared_error: 0.7193\n",
      "Epoch 90/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.2155 - mean_squared_error: 0.2155 - val_loss: 0.7467 - val_mean_squared_error: 0.7467\n",
      "Epoch 91/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.2073 - mean_squared_error: 0.2073 - val_loss: 0.7364 - val_mean_squared_error: 0.7364\n",
      "Epoch 92/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.2167 - mean_squared_error: 0.2167 - val_loss: 0.7439 - val_mean_squared_error: 0.7439\n",
      "Epoch 93/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.2112 - mean_squared_error: 0.2112 - val_loss: 0.7327 - val_mean_squared_error: 0.7327\n",
      "Epoch 94/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2146 - mean_squared_error: 0.2146 - val_loss: 0.7503 - val_mean_squared_error: 0.7503\n",
      "Epoch 95/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.2119 - mean_squared_error: 0.2119 - val_loss: 0.7455 - val_mean_squared_error: 0.7455\n",
      "Epoch 96/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.2052 - mean_squared_error: 0.2052 - val_loss: 0.7295 - val_mean_squared_error: 0.7295\n",
      "Epoch 97/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.2075 - mean_squared_error: 0.2075 - val_loss: 0.7239 - val_mean_squared_error: 0.7239\n",
      "Epoch 98/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.2037 - mean_squared_error: 0.2037 - val_loss: 0.7407 - val_mean_squared_error: 0.7407\n",
      "Epoch 99/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.2041 - mean_squared_error: 0.2041 - val_loss: 0.7302 - val_mean_squared_error: 0.7302\n",
      "Epoch 100/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.1994 - mean_squared_error: 0.1994 - val_loss: 0.7346 - val_mean_squared_error: 0.7346\n",
      "Epoch 101/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.2048 - mean_squared_error: 0.2048 - val_loss: 0.7179 - val_mean_squared_error: 0.7179\n",
      "Epoch 102/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.2004 - mean_squared_error: 0.2004 - val_loss: 0.7118 - val_mean_squared_error: 0.7118\n",
      "Epoch 103/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.2029 - mean_squared_error: 0.2029 - val_loss: 0.7426 - val_mean_squared_error: 0.7426\n",
      "Epoch 104/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.2023 - mean_squared_error: 0.2023 - val_loss: 0.7262 - val_mean_squared_error: 0.7262\n",
      "Epoch 105/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.2022 - mean_squared_error: 0.2022 - val_loss: 0.7576 - val_mean_squared_error: 0.7576\n",
      "Epoch 106/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.1939 - mean_squared_error: 0.1939 - val_loss: 0.7394 - val_mean_squared_error: 0.7394\n",
      "Epoch 107/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.1908 - mean_squared_error: 0.1908 - val_loss: 0.7417 - val_mean_squared_error: 0.7417\n",
      "Epoch 108/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.1884 - mean_squared_error: 0.1884 - val_loss: 0.7604 - val_mean_squared_error: 0.7604\n",
      "Epoch 109/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.1879 - mean_squared_error: 0.1879 - val_loss: 0.7441 - val_mean_squared_error: 0.7441\n",
      "Epoch 110/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.1862 - mean_squared_error: 0.1862 - val_loss: 0.7340 - val_mean_squared_error: 0.7340\n",
      "Epoch 110: early stopping\n",
      "Restoring model weights from the end of the best epoch: 60.\n"
     ]
    }
   ],
   "source": [
    "# Define Early Stopping callback\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=50,  # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=1000,  # Set a high number; EarlyStopping will halt training\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,  # 20% of training data used for validation\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd668536-460b-4eab-9d5f-a7331e6ba71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590us/step\n",
      "Final RMSE (with optimized rounding): 0.8783\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_continuous = model.predict(X_test_scaled).flatten()\n",
    "\n",
    "# Round predictions to nearest integer and clip to [0, 5]\n",
    "y_pred_rounded = np.clip(np.round(y_pred_continuous), 0, 5).astype(int)\n",
    "\n",
    "# Calculate RMSE\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rounded))\n",
    "print(f\"Final RMSE (with optimized rounding): {final_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d4730b7-034a-4718-a8ad-0486f8367a37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 27s]\n",
      "val_mean_squared_error: 1.2619692087173462\n",
      "\n",
      "Best val_mean_squared_error So Far: 0.7056520283222198\n",
      "Total elapsed time: 00h 16m 02s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first layer is 160,\n",
      "the dropout rate is 0.4, the number of units in the second layer is 32,\n",
      "the second dropout rate is 0.4, and the optimal learning rate for the optimizer is 0.001.\n",
      "\n",
      "Epoch 1/1000\n",
      "314/314 - 1s - 3ms/step - loss: 3.6200 - mean_squared_error: 3.6200 - val_loss: 1.5969 - val_mean_squared_error: 1.5969\n",
      "Epoch 2/1000\n",
      "314/314 - 0s - 1ms/step - loss: 1.8474 - mean_squared_error: 1.8474 - val_loss: 1.2091 - val_mean_squared_error: 1.2091\n",
      "Epoch 3/1000\n",
      "314/314 - 0s - 1ms/step - loss: 1.5218 - mean_squared_error: 1.5218 - val_loss: 1.0825 - val_mean_squared_error: 1.0825\n",
      "Epoch 4/1000\n",
      "314/314 - 0s - 1ms/step - loss: 1.3711 - mean_squared_error: 1.3711 - val_loss: 1.1135 - val_mean_squared_error: 1.1135\n",
      "Epoch 5/1000\n",
      "314/314 - 0s - 1ms/step - loss: 1.2707 - mean_squared_error: 1.2707 - val_loss: 0.9422 - val_mean_squared_error: 0.9422\n",
      "Epoch 6/1000\n",
      "314/314 - 0s - 1ms/step - loss: 1.1792 - mean_squared_error: 1.1792 - val_loss: 0.9340 - val_mean_squared_error: 0.9340\n",
      "Epoch 7/1000\n",
      "314/314 - 1s - 2ms/step - loss: 1.1080 - mean_squared_error: 1.1080 - val_loss: 0.9737 - val_mean_squared_error: 0.9737\n",
      "Epoch 8/1000\n",
      "314/314 - 1s - 2ms/step - loss: 1.0481 - mean_squared_error: 1.0481 - val_loss: 0.8821 - val_mean_squared_error: 0.8821\n",
      "Epoch 9/1000\n",
      "314/314 - 0s - 2ms/step - loss: 1.0095 - mean_squared_error: 1.0095 - val_loss: 0.8511 - val_mean_squared_error: 0.8511\n",
      "Epoch 10/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.9660 - mean_squared_error: 0.9660 - val_loss: 0.8537 - val_mean_squared_error: 0.8537\n",
      "Epoch 11/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.9320 - mean_squared_error: 0.9320 - val_loss: 0.8160 - val_mean_squared_error: 0.8160\n",
      "Epoch 12/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.8988 - mean_squared_error: 0.8988 - val_loss: 0.8534 - val_mean_squared_error: 0.8534\n",
      "Epoch 13/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.8600 - mean_squared_error: 0.8600 - val_loss: 0.8191 - val_mean_squared_error: 0.8191\n",
      "Epoch 14/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.8590 - mean_squared_error: 0.8590 - val_loss: 0.8150 - val_mean_squared_error: 0.8150\n",
      "Epoch 15/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.8360 - mean_squared_error: 0.8360 - val_loss: 0.8104 - val_mean_squared_error: 0.8104\n",
      "Epoch 16/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.8154 - mean_squared_error: 0.8154 - val_loss: 0.8062 - val_mean_squared_error: 0.8062\n",
      "Epoch 17/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.7875 - mean_squared_error: 0.7875 - val_loss: 0.7879 - val_mean_squared_error: 0.7879\n",
      "Epoch 18/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.7676 - mean_squared_error: 0.7676 - val_loss: 0.7913 - val_mean_squared_error: 0.7913\n",
      "Epoch 19/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.7600 - mean_squared_error: 0.7600 - val_loss: 0.7667 - val_mean_squared_error: 0.7667\n",
      "Epoch 20/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.7374 - mean_squared_error: 0.7374 - val_loss: 0.7705 - val_mean_squared_error: 0.7705\n",
      "Epoch 21/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.7271 - mean_squared_error: 0.7271 - val_loss: 0.7752 - val_mean_squared_error: 0.7752\n",
      "Epoch 22/1000\n",
      "314/314 - 1s - 2ms/step - loss: 0.7157 - mean_squared_error: 0.7157 - val_loss: 0.7578 - val_mean_squared_error: 0.7578\n",
      "Epoch 23/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.6996 - mean_squared_error: 0.6996 - val_loss: 0.7627 - val_mean_squared_error: 0.7627\n",
      "Epoch 24/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.7023 - mean_squared_error: 0.7023 - val_loss: 0.7389 - val_mean_squared_error: 0.7389\n",
      "Epoch 25/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.6595 - mean_squared_error: 0.6595 - val_loss: 0.7506 - val_mean_squared_error: 0.7506\n",
      "Epoch 26/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.6694 - mean_squared_error: 0.6694 - val_loss: 0.7442 - val_mean_squared_error: 0.7442\n",
      "Epoch 27/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.6586 - mean_squared_error: 0.6586 - val_loss: 0.7334 - val_mean_squared_error: 0.7334\n",
      "Epoch 28/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.6427 - mean_squared_error: 0.6427 - val_loss: 0.7444 - val_mean_squared_error: 0.7444\n",
      "Epoch 29/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.6339 - mean_squared_error: 0.6339 - val_loss: 0.7232 - val_mean_squared_error: 0.7232\n",
      "Epoch 30/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.6344 - mean_squared_error: 0.6344 - val_loss: 0.7339 - val_mean_squared_error: 0.7339\n",
      "Epoch 31/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.6175 - mean_squared_error: 0.6175 - val_loss: 0.7302 - val_mean_squared_error: 0.7302\n",
      "Epoch 32/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.6094 - mean_squared_error: 0.6094 - val_loss: 0.7300 - val_mean_squared_error: 0.7300\n",
      "Epoch 33/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.6115 - mean_squared_error: 0.6115 - val_loss: 0.7326 - val_mean_squared_error: 0.7326\n",
      "Epoch 34/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.5965 - mean_squared_error: 0.5965 - val_loss: 0.7387 - val_mean_squared_error: 0.7387\n",
      "Epoch 35/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.5818 - mean_squared_error: 0.5818 - val_loss: 0.7184 - val_mean_squared_error: 0.7184\n",
      "Epoch 36/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.5721 - mean_squared_error: 0.5721 - val_loss: 0.7271 - val_mean_squared_error: 0.7271\n",
      "Epoch 37/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.5695 - mean_squared_error: 0.5695 - val_loss: 0.7477 - val_mean_squared_error: 0.7477\n",
      "Epoch 38/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.5719 - mean_squared_error: 0.5719 - val_loss: 0.7224 - val_mean_squared_error: 0.7224\n",
      "Epoch 39/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.5549 - mean_squared_error: 0.5549 - val_loss: 0.7270 - val_mean_squared_error: 0.7270\n",
      "Epoch 40/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.5499 - mean_squared_error: 0.5499 - val_loss: 0.7355 - val_mean_squared_error: 0.7355\n",
      "Epoch 41/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.5566 - mean_squared_error: 0.5566 - val_loss: 0.7502 - val_mean_squared_error: 0.7502\n",
      "Epoch 42/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.5457 - mean_squared_error: 0.5457 - val_loss: 0.7332 - val_mean_squared_error: 0.7332\n",
      "Epoch 43/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.5306 - mean_squared_error: 0.5306 - val_loss: 0.7247 - val_mean_squared_error: 0.7247\n",
      "Epoch 44/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.5352 - mean_squared_error: 0.5352 - val_loss: 0.7291 - val_mean_squared_error: 0.7291\n",
      "Epoch 45/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.5243 - mean_squared_error: 0.5243 - val_loss: 0.7323 - val_mean_squared_error: 0.7323\n",
      "Epoch 46/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.5097 - mean_squared_error: 0.5097 - val_loss: 0.7193 - val_mean_squared_error: 0.7193\n",
      "Epoch 47/1000\n",
      "314/314 - 0s - 1ms/step - loss: 0.5159 - mean_squared_error: 0.5159 - val_loss: 0.7177 - val_mean_squared_error: 0.7177\n",
      "Epoch 48/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.5125 - mean_squared_error: 0.5125 - val_loss: 0.7293 - val_mean_squared_error: 0.7293\n",
      "Epoch 49/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.5045 - mean_squared_error: 0.5045 - val_loss: 0.7258 - val_mean_squared_error: 0.7258\n",
      "Epoch 50/1000\n",
      "314/314 - 0s - 2ms/step - loss: 0.4961 - mean_squared_error: 0.4961 - val_loss: 0.7298 - val_mean_squared_error: 0.7298\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step\n",
      "Final RMSE after hyperparameter tuning: 1.2564\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "    # Tune the number of units in the first Dense layer\n",
    "    hp_units = hp.Int('units1', min_value=64, max_value=256, step=32)\n",
    "    model.add(Dense(units=hp_units, activation='relu', input_dim=input_dim))\n",
    "    \n",
    "    # Tune the dropout rate\n",
    "    hp_dropout = hp.Float('dropout1', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    model.add(Dropout(rate=hp_dropout))\n",
    "    \n",
    "    # Add a second Dense layer\n",
    "    hp_units2 = hp.Int('units2', min_value=32, max_value=128, step=32)\n",
    "    model.add(Dense(units=hp_units2, activation='relu'))\n",
    "    \n",
    "    # Tune the second dropout rate\n",
    "    hp_dropout2 = hp.Float('dropout2', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    model.add(Dropout(rate=hp_dropout2))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    # Tune the learning rate for the optimizer\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mean_squared_error']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    model_builder,\n",
    "    objective='val_mean_squared_error',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='airbnb_price_prediction'\n",
    ")\n",
    "\n",
    "# Display search space summary\n",
    "tuner.search_space_summary()\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first layer is {best_hps.get('units1')},\n",
    "the dropout rate is {best_hps.get('dropout1')}, the number of units in the second layer is {best_hps.get('units2')},\n",
    "the second dropout rate is {best_hps.get('dropout2')}, and the optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
    "\"\"\")\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it\n",
    "optimized_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "history = optimized_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Make predictions with the optimized model\n",
    "y_pred_continuous_opt = optimized_model.predict(X_test_scaled).flatten()\n",
    "y_pred_rounded_opt = np.clip(np.round(y_pred_continuous_opt), 0, 5).astype(int)\n",
    "\n",
    "# Calculate RMSE for the optimized model\n",
    "final_rmse_opt = np.sqrt(mean_squared_error(y_test, y_pred_rounded_opt))\n",
    "print(f\"Final RMSE after hyperparameter tuning: {final_rmse_opt:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34ddea1c-1c16-4006-9f7d-8691d9251a73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"latitude, longitude, host_since, host_response_rate, host_acceptance_rate, host_is_superhost, host_listings_count, host_total_listings_count, host_has_profile_pic, host_identity_verified, calculated_host_listings_count, calculated_host_listings_count_entire_homes, calculated_host_listings_count_private_rooms, calculated_host_listings_count_shared_rooms, accommodates, bathrooms, bedrooms, beds, availability_30, availability_60, availability_90, availability_365, instant_bookable, minimum_nights, maximum_nights, number_of_reviews, number_of_reviews_ltm, number_of_reviews_l30d, first_review, last_review, review_scores_rating, review_scores_accuracy, review_scores_cleanliness, review_scores_checkin, review_scores_communication, review_scores_location, review_scores_value, reviews_per_month, shared_bathrooms, has_washer, has_dryer, has_dishwasher, has_freezer, has_bbq_grill, has_hot_tub, has_pool, has_gym, has_balcony, has_backyard, amenities_count, description_length, name_length, neighbourhood_cleansed_Allerton, neighbourhood_cleansed_Arrochar, neighbourhood_cleansed_Arverne, neighbourhood_cleansed_Astoria, neighbourhood_cleansed_Bath Beach, neighbourhood_cleansed_Battery Park City, neighbourhood_cleansed_Bay Ridge, neighbourhood_cleansed_Baychester, neighbourhood_cleansed_Bayside, neighbourhood_cleansed_Bayswater, neighbourhood_cleansed_Bedford-Stuyvesant, neighbourhood_cleansed_Belle Harbor, neighbourhood_cleansed_Bellerose, neighbourhood_cleansed_Belmont, neighbourhood_cleansed_Bensonhurst, neighbourhood_cleansed_Bergen Beach, neighbourhood_cleansed_Boerum Hill, neighbourhood_cleansed_Borough Park, neighbourhood_cleansed_Briarwood, neighbourhood_cleansed_Brighton Beach, neighbourhood_cleansed_Bronxdale, neighbourhood_cleansed_Brooklyn Heights, neighbourhood_cleansed_Brownsville, neighbourhood_cleansed_Bull's Head, neighbourhood_cleansed_Bushwick, neighbourhood_cleansed_Cambria Heights, neighbourhood_cleansed_Canarsie, neighbourhood_cleansed_Carroll Gardens, neighbourhood_cleansed_Castle Hill, neighbourhood_cleansed_Chelsea, neighbourhood_cleansed_Chinatown, neighbourhood_cleansed_City Island, neighbourhood_cleansed_Civic Center, neighbourhood_cleansed_Claremont Village, neighbourhood_cleansed_Clason Point, neighbourhood_cleansed_Clifton, neighbourhood_cleansed_Clinton Hill, neighbourhood_cleansed_Co-op City, neighbourhood_cleansed_Cobble Hill, neighbourhood_cleansed_College Point, neighbourhood_cleansed_Columbia St, neighbourhood_cleansed_Concourse, neighbourhood_cleansed_Concourse Village, neighbourhood_cleansed_Coney Island, neighbourhood_cleansed_Corona, neighbourhood_cleansed_Crown Heights, neighbourhood_cleansed_Cypress Hills, neighbourhood_cleansed_DUMBO, neighbourhood_cleansed_Ditmars Steinway, neighbourhood_cleansed_Downtown Brooklyn, neighbourhood_cleansed_Dyker Heights, neighbourhood_cleansed_East Elmhurst, neighbourhood_cleansed_East Flatbush, neighbourhood_cleansed_East Harlem, neighbourhood_cleansed_East New York, neighbourhood_cleansed_East Village, neighbourhood_cleansed_Eastchester, neighbourhood_cleansed_Edenwald, neighbourhood_cleansed_Edgemere, neighbourhood_cleansed_Elmhurst, neighbourhood_cleansed_Far Rockaway, neighbourhood_cleansed_Fieldston, neighbourhood_cleansed_Financial District, neighbourhood_cleansed_Flatbush, neighbourhood_cleansed_Flatiron District, neighbourhood_cleansed_Flatlands, neighbourhood_cleansed_Flushing, neighbourhood_cleansed_Fordham, neighbourhood_cleansed_Forest Hills, neighbourhood_cleansed_Fort Greene, neighbourhood_cleansed_Fort Hamilton, neighbourhood_cleansed_Fresh Meadows, neighbourhood_cleansed_Glendale, neighbourhood_cleansed_Gowanus, neighbourhood_cleansed_Gramercy, neighbourhood_cleansed_Grant City, neighbourhood_cleansed_Gravesend, neighbourhood_cleansed_Greenpoint, neighbourhood_cleansed_Greenwich Village, neighbourhood_cleansed_Harlem, neighbourhood_cleansed_Hell's Kitchen, neighbourhood_cleansed_Highbridge, neighbourhood_cleansed_Hollis, neighbourhood_cleansed_Howard Beach, neighbourhood_cleansed_Hunts Point, neighbourhood_cleansed_Inwood, neighbourhood_cleansed_Jackson Heights, neighbourhood_cleansed_Jamaica, neighbourhood_cleansed_Jamaica Estates, neighbourhood_cleansed_Jamaica Hills, neighbourhood_cleansed_Kensington, neighbourhood_cleansed_Kew Gardens, neighbourhood_cleansed_Kew Gardens Hills, neighbourhood_cleansed_Kingsbridge, neighbourhood_cleansed_Kips Bay, neighbourhood_cleansed_Laurelton, neighbourhood_cleansed_Little Italy, neighbourhood_cleansed_Little Neck, neighbourhood_cleansed_Long Island City, neighbourhood_cleansed_Longwood, neighbourhood_cleansed_Lower East Side, neighbourhood_cleansed_Mariners Harbor, neighbourhood_cleansed_Maspeth, neighbourhood_cleansed_Melrose, neighbourhood_cleansed_Middle Village, neighbourhood_cleansed_Midland Beach, neighbourhood_cleansed_Midtown, neighbourhood_cleansed_Midwood, neighbourhood_cleansed_Mill Basin, neighbourhood_cleansed_Morningside Heights, neighbourhood_cleansed_Morris Heights, neighbourhood_cleansed_Morris Park, neighbourhood_cleansed_Morrisania, neighbourhood_cleansed_Mott Haven, neighbourhood_cleansed_Mount Hope, neighbourhood_cleansed_Murray Hill, neighbourhood_cleansed_NoHo, neighbourhood_cleansed_Nolita, neighbourhood_cleansed_North Riverdale, neighbourhood_cleansed_Norwood, neighbourhood_cleansed_Ozone Park, neighbourhood_cleansed_Park Slope, neighbourhood_cleansed_Parkchester, neighbourhood_cleansed_Pelham Bay, neighbourhood_cleansed_Pelham Gardens, neighbourhood_cleansed_Port Morris, neighbourhood_cleansed_Port Richmond, neighbourhood_cleansed_Prospect Heights, neighbourhood_cleansed_Prospect-Lefferts Gardens, neighbourhood_cleansed_Queens Village, neighbourhood_cleansed_Randall Manor, neighbourhood_cleansed_Red Hook, neighbourhood_cleansed_Rego Park, neighbourhood_cleansed_Richmond Hill, neighbourhood_cleansed_Ridgewood, neighbourhood_cleansed_Rockaway Beach, neighbourhood_cleansed_Roosevelt Island, neighbourhood_cleansed_Rosedale, neighbourhood_cleansed_Schuylerville, neighbourhood_cleansed_Sea Gate, neighbourhood_cleansed_Sheepshead Bay, neighbourhood_cleansed_Shore Acres, neighbourhood_cleansed_SoHo, neighbourhood_cleansed_Soundview, neighbourhood_cleansed_South Beach, neighbourhood_cleansed_South Ozone Park, neighbourhood_cleansed_South Slope, neighbourhood_cleansed_Springfield Gardens, neighbourhood_cleansed_Spuyten Duyvil, neighbourhood_cleansed_St. Albans, neighbourhood_cleansed_St. George, neighbourhood_cleansed_Stapleton, neighbourhood_cleansed_Stuyvesant Town, neighbourhood_cleansed_Sunnyside, neighbourhood_cleansed_Sunset Park, neighbourhood_cleansed_Theater District, neighbourhood_cleansed_Throgs Neck, neighbourhood_cleansed_Tompkinsville, neighbourhood_cleansed_Tremont, neighbourhood_cleansed_Tribeca, neighbourhood_cleansed_Two Bridges, neighbourhood_cleansed_Unionport, neighbourhood_cleansed_Upper East Side, neighbourhood_cleansed_Upper West Side, neighbourhood_cleansed_Van Nest, neighbourhood_cleansed_Vinegar Hill, neighbourhood_cleansed_Wakefield, neighbourhood_cleansed_Washington Heights, neighbourhood_cleansed_West Brighton, neighbourhood_cleansed_West Village, neighbourhood_cleansed_Whitestone, neighbourhood_cleansed_Williamsbridge, neighbourhood_cleansed_Williamsburg, neighbourhood_cleansed_Windsor Terrace, neighbourhood_cleansed_Woodhaven, neighbourhood_cleansed_Woodlawn, neighbourhood_cleansed_Woodside, neighbourhood_cleansed_infrequent_sklearn, neighbourhood_group_cleansed_Bronx, neighbourhood_group_cleansed_Brooklyn, neighbourhood_group_cleansed_Manhattan, neighbourhood_group_cleansed_Queens, neighbourhood_group_cleansed_Staten Island, host_response_time_a few days or more, host_response_time_within a day, host_response_time_within a few hours, host_response_time_within an hour, host_response_time_nan, room_type_Entire home/apt, room_type_Hotel room, room_type_Private room, room_type_Shared room, location_cluster_0, location_cluster_1, location_cluster_2, location_cluster_3, location_cluster_4, location_cluster_5, location_cluster_6, location_cluster_7, location_cluster_8, location_cluster_9, location_cluster_10, location_cluster_11, location_cluster_12, location_cluster_13, location_cluster_14, location_cluster_15, location_cluster_16, location_cluster_17, location_cluster_18, location_cluster_19, location_cluster_20, location_cluster_21, location_cluster_22, location_cluster_23, location_cluster_25, location_cluster_26, location_cluster_27, location_cluster_28, location_cluster_29, location_cluster_30, location_cluster_31, location_cluster_32, location_cluster_33, location_cluster_34, location_cluster_35, location_cluster_36, location_cluster_37, location_cluster_38, location_cluster_39, location_cluster_40, location_cluster_41, location_cluster_42, location_cluster_43, location_cluster_44, location_cluster_45, location_cluster_46, location_cluster_47, location_cluster_48, location_cluster_49, location_cluster_50, location_cluster_51, location_cluster_52, location_cluster_53, location_cluster_54, location_cluster_55, location_cluster_56, location_cluster_57, location_cluster_58, location_cluster_59, location_cluster_60, location_cluster_61, location_cluster_62, location_cluster_63, location_cluster_64, location_cluster_65, location_cluster_66, location_cluster_67, location_cluster_68, location_cluster_69, location_cluster_70, location_cluster_71, location_cluster_72, location_cluster_73, location_cluster_74, location_cluster_75, location_cluster_76, location_cluster_78, location_cluster_79, location_cluster_80, location_cluster_81, location_cluster_82, location_cluster_83, location_cluster_84, location_cluster_85, location_cluster_86, location_cluster_87, location_cluster_88, location_cluster_89, location_cluster_90, location_cluster_91, location_cluster_92, location_cluster_93, location_cluster_94, location_cluster_95, location_cluster_96, location_cluster_97, location_cluster_98, location_cluster_99, location_cluster_100, location_cluster_101, location_cluster_102, location_cluster_103, location_cluster_104, location_cluster_105, location_cluster_106, location_cluster_107, location_cluster_109, location_cluster_110, location_cluster_111, location_cluster_112, location_cluster_113, location_cluster_114, location_cluster_115, location_cluster_116, location_cluster_117, location_cluster_118, location_cluster_119, location_cluster_120, location_cluster_121, location_cluster_122, location_cluster_123, location_cluster_124, location_cluster_125, location_cluster_126, location_cluster_127, location_cluster_128, location_cluster_129, location_cluster_130, location_cluster_131, location_cluster_132, location_cluster_133, location_cluster_134, location_cluster_136, location_cluster_137, location_cluster_138, location_cluster_139, location_cluster_140, location_cluster_141, location_cluster_142, location_cluster_143, location_cluster_144, location_cluster_145, location_cluster_146, location_cluster_147, location_cluster_148, location_cluster_149, location_cluster_150, location_cluster_151, location_cluster_152, location_cluster_153, location_cluster_155, location_cluster_156, location_cluster_157, location_cluster_158, location_cluster_159, location_cluster_160, location_cluster_161, location_cluster_162, location_cluster_163, location_cluster_164, location_cluster_165, location_cluster_166, location_cluster_167, location_cluster_168, location_cluster_169, location_cluster_170, location_cluster_171, location_cluster_172, location_cluster_173, location_cluster_174, location_cluster_175, location_cluster_176, location_cluster_177, location_cluster_178, location_cluster_179, location_cluster_180, location_cluster_181, location_cluster_182, location_cluster_183, location_cluster_184, location_cluster_185, location_cluster_186, location_cluster_187, location_cluster_188, location_cluster_189, location_cluster_190, location_cluster_191, location_cluster_192, location_cluster_193, location_cluster_194, location_cluster_195, location_cluster_196, location_cluster_197, location_cluster_198, location_cluster_199, location_cluster_200, location_cluster_201, location_cluster_202, location_cluster_203, location_cluster_204, location_cluster_205, location_cluster_206, location_cluster_208, location_cluster_209, location_cluster_210, location_cluster_211, location_cluster_212, location_cluster_213, location_cluster_214, location_cluster_215, location_cluster_216, location_cluster_217, location_cluster_218, location_cluster_219, location_cluster_220, location_cluster_221, location_cluster_222, location_cluster_223, location_cluster_224, location_cluster_225, location_cluster_226, location_cluster_227, location_cluster_228, location_cluster_229, location_cluster_230, location_cluster_231, location_cluster_232, location_cluster_233, location_cluster_234, location_cluster_235, location_cluster_236, location_cluster_237, location_cluster_238, location_cluster_239, location_cluster_240, location_cluster_241, location_cluster_242, location_cluster_243, location_cluster_244, location_cluster_245, location_cluster_246, location_cluster_247, location_cluster_248, location_cluster_249, location_cluster_250, location_cluster_251, location_cluster_252, location_cluster_253, location_cluster_254, location_cluster_255, location_cluster_256, location_cluster_257, location_cluster_258, location_cluster_259, location_cluster_260, location_cluster_261, location_cluster_262, location_cluster_263, location_cluster_264, location_cluster_265, location_cluster_267, location_cluster_268, location_cluster_269, location_cluster_270, location_cluster_271, location_cluster_272, location_cluster_273, location_cluster_274, location_cluster_275, location_cluster_276, location_cluster_277, location_cluster_278, location_cluster_279, location_cluster_280, location_cluster_281, location_cluster_282, location_cluster_283, location_cluster_284, location_cluster_285, location_cluster_286, location_cluster_287, location_cluster_288, location_cluster_289, location_cluster_290, location_cluster_291, location_cluster_292, location_cluster_293, location_cluster_294, location_cluster_295, location_cluster_296, location_cluster_297, location_cluster_298, location_cluster_299, location_cluster_infrequent_sklearn\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5259cb6e-b441-4bc3-8f52-26d3e7b17b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethan/miniconda3/envs/cs671/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/ethan/miniconda3/envs/cs671/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">275,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m275,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">452,353</span> (1.73 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m452,353\u001b[0m (1.73 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">450,433</span> (1.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m450,433\u001b[0m (1.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_enhanced_model(input_dim):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # First Hidden Layer\n",
    "    model.add(Dense(512, input_dim=input_dim))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # Second Hidden Layer\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    # Third Hidden Layer\n",
    "    model.add(Dense(128))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    # Fourth Hidden Layer\n",
    "    model.add(Dense(64))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Output Layer\n",
    "    model.add(Dense(1, activation='linear'))  # For regression\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mean_squared_error']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Get the number of input features\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "\n",
    "# Build the model\n",
    "model = build_enhanced_model(input_dim)\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e848aa1-33f9-40a8-a784-095f75427cb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "157/157 - 2s - 15ms/step - loss: 5.7749 - mean_squared_error: 5.7749 - val_loss: 2.0345 - val_mean_squared_error: 2.0345\n",
      "Epoch 2/500\n",
      "157/157 - 1s - 7ms/step - loss: 2.1549 - mean_squared_error: 2.1549 - val_loss: 1.0199 - val_mean_squared_error: 1.0199\n",
      "Epoch 3/500\n",
      "157/157 - 1s - 9ms/step - loss: 1.5960 - mean_squared_error: 1.5960 - val_loss: 0.9217 - val_mean_squared_error: 0.9217\n",
      "Epoch 4/500\n",
      "157/157 - 1s - 7ms/step - loss: 1.3585 - mean_squared_error: 1.3585 - val_loss: 0.9215 - val_mean_squared_error: 0.9215\n",
      "Epoch 5/500\n",
      "157/157 - 1s - 7ms/step - loss: 1.2338 - mean_squared_error: 1.2338 - val_loss: 0.8903 - val_mean_squared_error: 0.8903\n",
      "Epoch 6/500\n",
      "157/157 - 1s - 6ms/step - loss: 1.1335 - mean_squared_error: 1.1335 - val_loss: 0.8876 - val_mean_squared_error: 0.8876\n",
      "Epoch 7/500\n",
      "157/157 - 1s - 7ms/step - loss: 1.0725 - mean_squared_error: 1.0725 - val_loss: 0.8665 - val_mean_squared_error: 0.8665\n",
      "Epoch 8/500\n",
      "157/157 - 1s - 8ms/step - loss: 1.0162 - mean_squared_error: 1.0162 - val_loss: 0.8594 - val_mean_squared_error: 0.8594\n",
      "Epoch 9/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.9702 - mean_squared_error: 0.9702 - val_loss: 0.8374 - val_mean_squared_error: 0.8374\n",
      "Epoch 10/500\n",
      "157/157 - 1s - 8ms/step - loss: 0.9276 - mean_squared_error: 0.9276 - val_loss: 0.8222 - val_mean_squared_error: 0.8222\n",
      "Epoch 11/500\n",
      "157/157 - 1s - 8ms/step - loss: 0.8825 - mean_squared_error: 0.8825 - val_loss: 0.8050 - val_mean_squared_error: 0.8050\n",
      "Epoch 12/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.8656 - mean_squared_error: 0.8656 - val_loss: 0.8027 - val_mean_squared_error: 0.8027\n",
      "Epoch 13/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.8473 - mean_squared_error: 0.8473 - val_loss: 0.7860 - val_mean_squared_error: 0.7860\n",
      "Epoch 14/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.8353 - mean_squared_error: 0.8353 - val_loss: 0.7918 - val_mean_squared_error: 0.7918\n",
      "Epoch 15/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.8035 - mean_squared_error: 0.8035 - val_loss: 0.7785 - val_mean_squared_error: 0.7785\n",
      "Epoch 16/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.7844 - mean_squared_error: 0.7844 - val_loss: 0.7846 - val_mean_squared_error: 0.7846\n",
      "Epoch 17/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.7571 - mean_squared_error: 0.7571 - val_loss: 0.7777 - val_mean_squared_error: 0.7777\n",
      "Epoch 18/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.7534 - mean_squared_error: 0.7534 - val_loss: 0.7574 - val_mean_squared_error: 0.7574\n",
      "Epoch 19/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.7375 - mean_squared_error: 0.7375 - val_loss: 0.7535 - val_mean_squared_error: 0.7535\n",
      "Epoch 20/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.7249 - mean_squared_error: 0.7249 - val_loss: 0.7478 - val_mean_squared_error: 0.7478\n",
      "Epoch 21/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.7134 - mean_squared_error: 0.7134 - val_loss: 0.7583 - val_mean_squared_error: 0.7583\n",
      "Epoch 22/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.6828 - mean_squared_error: 0.6828 - val_loss: 0.7618 - val_mean_squared_error: 0.7618\n",
      "Epoch 23/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.6764 - mean_squared_error: 0.6764 - val_loss: 0.7422 - val_mean_squared_error: 0.7422\n",
      "Epoch 24/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.6612 - mean_squared_error: 0.6612 - val_loss: 0.7379 - val_mean_squared_error: 0.7379\n",
      "Epoch 25/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.6551 - mean_squared_error: 0.6551 - val_loss: 0.7314 - val_mean_squared_error: 0.7314\n",
      "Epoch 26/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.6480 - mean_squared_error: 0.6480 - val_loss: 0.7316 - val_mean_squared_error: 0.7316\n",
      "Epoch 27/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.6385 - mean_squared_error: 0.6385 - val_loss: 0.7490 - val_mean_squared_error: 0.7490\n",
      "Epoch 28/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.6264 - mean_squared_error: 0.6264 - val_loss: 0.7276 - val_mean_squared_error: 0.7276\n",
      "Epoch 29/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.6245 - mean_squared_error: 0.6245 - val_loss: 0.7124 - val_mean_squared_error: 0.7124\n",
      "Epoch 30/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.6066 - mean_squared_error: 0.6066 - val_loss: 0.7285 - val_mean_squared_error: 0.7285\n",
      "Epoch 31/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.5899 - mean_squared_error: 0.5899 - val_loss: 0.7233 - val_mean_squared_error: 0.7233\n",
      "Epoch 32/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.5980 - mean_squared_error: 0.5980 - val_loss: 0.7323 - val_mean_squared_error: 0.7323\n",
      "Epoch 33/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.5697 - mean_squared_error: 0.5697 - val_loss: 0.7169 - val_mean_squared_error: 0.7169\n",
      "Epoch 34/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.5719 - mean_squared_error: 0.5719 - val_loss: 0.7342 - val_mean_squared_error: 0.7342\n",
      "Epoch 35/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.5653 - mean_squared_error: 0.5653 - val_loss: 0.7058 - val_mean_squared_error: 0.7058\n",
      "Epoch 36/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.5580 - mean_squared_error: 0.5580 - val_loss: 0.7437 - val_mean_squared_error: 0.7437\n",
      "Epoch 37/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.5607 - mean_squared_error: 0.5607 - val_loss: 0.7197 - val_mean_squared_error: 0.7197\n",
      "Epoch 38/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.5579 - mean_squared_error: 0.5579 - val_loss: 0.7243 - val_mean_squared_error: 0.7243\n",
      "Epoch 39/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.5411 - mean_squared_error: 0.5411 - val_loss: 0.7156 - val_mean_squared_error: 0.7156\n",
      "Epoch 40/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.5436 - mean_squared_error: 0.5436 - val_loss: 0.7105 - val_mean_squared_error: 0.7105\n",
      "Epoch 41/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.5384 - mean_squared_error: 0.5384 - val_loss: 0.7339 - val_mean_squared_error: 0.7339\n",
      "Epoch 42/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.5177 - mean_squared_error: 0.5177 - val_loss: 0.7268 - val_mean_squared_error: 0.7268\n",
      "Epoch 43/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.5133 - mean_squared_error: 0.5133 - val_loss: 0.7130 - val_mean_squared_error: 0.7130\n",
      "Epoch 44/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4994 - mean_squared_error: 0.4994 - val_loss: 0.7149 - val_mean_squared_error: 0.7149\n",
      "Epoch 45/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.5097 - mean_squared_error: 0.5097 - val_loss: 0.7108 - val_mean_squared_error: 0.7108\n",
      "Epoch 46/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.4936 - mean_squared_error: 0.4936 - val_loss: 0.7224 - val_mean_squared_error: 0.7224\n",
      "Epoch 47/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.4834 - mean_squared_error: 0.4834 - val_loss: 0.7110 - val_mean_squared_error: 0.7110\n",
      "Epoch 48/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.4808 - mean_squared_error: 0.4808 - val_loss: 0.7160 - val_mean_squared_error: 0.7160\n",
      "Epoch 49/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.4855 - mean_squared_error: 0.4855 - val_loss: 0.7267 - val_mean_squared_error: 0.7267\n",
      "Epoch 50/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.4940 - mean_squared_error: 0.4940 - val_loss: 0.6922 - val_mean_squared_error: 0.6922\n",
      "Epoch 51/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4821 - mean_squared_error: 0.4821 - val_loss: 0.7057 - val_mean_squared_error: 0.7057\n",
      "Epoch 52/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4670 - mean_squared_error: 0.4670 - val_loss: 0.7101 - val_mean_squared_error: 0.7101\n",
      "Epoch 53/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4796 - mean_squared_error: 0.4796 - val_loss: 0.7010 - val_mean_squared_error: 0.7010\n",
      "Epoch 54/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4645 - mean_squared_error: 0.4645 - val_loss: 0.6955 - val_mean_squared_error: 0.6955\n",
      "Epoch 55/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4625 - mean_squared_error: 0.4625 - val_loss: 0.7261 - val_mean_squared_error: 0.7261\n",
      "Epoch 56/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4615 - mean_squared_error: 0.4615 - val_loss: 0.7034 - val_mean_squared_error: 0.7034\n",
      "Epoch 57/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.4485 - mean_squared_error: 0.4485 - val_loss: 0.6892 - val_mean_squared_error: 0.6892\n",
      "Epoch 58/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4373 - mean_squared_error: 0.4373 - val_loss: 0.7011 - val_mean_squared_error: 0.7011\n",
      "Epoch 59/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4205 - mean_squared_error: 0.4205 - val_loss: 0.6953 - val_mean_squared_error: 0.6953\n",
      "Epoch 60/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.4361 - mean_squared_error: 0.4361 - val_loss: 0.6929 - val_mean_squared_error: 0.6929\n",
      "Epoch 61/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4238 - mean_squared_error: 0.4238 - val_loss: 0.7313 - val_mean_squared_error: 0.7313\n",
      "Epoch 62/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4369 - mean_squared_error: 0.4369 - val_loss: 0.7131 - val_mean_squared_error: 0.7131\n",
      "Epoch 63/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4304 - mean_squared_error: 0.4304 - val_loss: 0.7196 - val_mean_squared_error: 0.7196\n",
      "Epoch 64/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4108 - mean_squared_error: 0.4108 - val_loss: 0.7223 - val_mean_squared_error: 0.7223\n",
      "Epoch 65/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4126 - mean_squared_error: 0.4126 - val_loss: 0.7342 - val_mean_squared_error: 0.7342\n",
      "Epoch 66/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4307 - mean_squared_error: 0.4307 - val_loss: 0.7166 - val_mean_squared_error: 0.7166\n",
      "Epoch 67/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.3998 - mean_squared_error: 0.3998 - val_loss: 0.6980 - val_mean_squared_error: 0.6980\n",
      "Epoch 68/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.4017 - mean_squared_error: 0.4017 - val_loss: 0.7113 - val_mean_squared_error: 0.7113\n",
      "Epoch 69/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4011 - mean_squared_error: 0.4011 - val_loss: 0.7085 - val_mean_squared_error: 0.7085\n",
      "Epoch 70/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.3978 - mean_squared_error: 0.3978 - val_loss: 0.7213 - val_mean_squared_error: 0.7213\n",
      "Epoch 71/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4007 - mean_squared_error: 0.4007 - val_loss: 0.7009 - val_mean_squared_error: 0.7009\n",
      "Epoch 72/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.4039 - mean_squared_error: 0.4039 - val_loss: 0.6956 - val_mean_squared_error: 0.6956\n",
      "Epoch 73/500\n",
      "157/157 - 1s - 8ms/step - loss: 0.4018 - mean_squared_error: 0.4018 - val_loss: 0.7273 - val_mean_squared_error: 0.7273\n",
      "Epoch 74/500\n",
      "157/157 - 1s - 9ms/step - loss: 0.3859 - mean_squared_error: 0.3859 - val_loss: 0.7109 - val_mean_squared_error: 0.7109\n",
      "Epoch 75/500\n",
      "157/157 - 1s - 8ms/step - loss: 0.3805 - mean_squared_error: 0.3805 - val_loss: 0.6992 - val_mean_squared_error: 0.6992\n",
      "Epoch 76/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.3776 - mean_squared_error: 0.3776 - val_loss: 0.7033 - val_mean_squared_error: 0.7033\n",
      "Epoch 77/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.3680 - mean_squared_error: 0.3680 - val_loss: 0.6938 - val_mean_squared_error: 0.6938\n",
      "Epoch 78/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.3758 - mean_squared_error: 0.3758 - val_loss: 0.7124 - val_mean_squared_error: 0.7124\n",
      "Epoch 79/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.3691 - mean_squared_error: 0.3691 - val_loss: 0.6951 - val_mean_squared_error: 0.6951\n",
      "Epoch 80/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.3698 - mean_squared_error: 0.3698 - val_loss: 0.7027 - val_mean_squared_error: 0.7027\n",
      "Epoch 81/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.3703 - mean_squared_error: 0.3703 - val_loss: 0.7170 - val_mean_squared_error: 0.7170\n",
      "Epoch 82/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.3771 - mean_squared_error: 0.3771 - val_loss: 0.7433 - val_mean_squared_error: 0.7433\n",
      "Epoch 83/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.3706 - mean_squared_error: 0.3706 - val_loss: 0.7074 - val_mean_squared_error: 0.7074\n",
      "Epoch 84/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.3639 - mean_squared_error: 0.3639 - val_loss: 0.7164 - val_mean_squared_error: 0.7164\n",
      "Epoch 85/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.3662 - mean_squared_error: 0.3662 - val_loss: 0.7204 - val_mean_squared_error: 0.7204\n",
      "Epoch 86/500\n",
      "157/157 - 1s - 6ms/step - loss: 0.3620 - mean_squared_error: 0.3620 - val_loss: 0.7251 - val_mean_squared_error: 0.7251\n",
      "Epoch 87/500\n",
      "157/157 - 1s - 7ms/step - loss: 0.3614 - mean_squared_error: 0.3614 - val_loss: 0.7233 - val_mean_squared_error: 0.7233\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n"
     ]
    }
   ],
   "source": [
    "# Define Early Stopping callback\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=30,  # Adjust based on your observations\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=500,  # High number with early stopping\n",
    "    batch_size=64,  # Larger batch size due to high dimensionality\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5af50fc-99e7-456f-a5a1-ae2df4b6a451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Final RMSE (with optimized rounding): 0.8682\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_continuous = model.predict(X_test_scaled).flatten()\n",
    "\n",
    "# Round predictions to nearest integer and clip to [0, 5]\n",
    "y_pred_rounded = np.clip(np.round(y_pred_continuous), 0, 5).astype(int)\n",
    "\n",
    "# Calculate RMSE\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rounded))\n",
    "print(f\"Final RMSE (with optimized rounding): {final_rmse:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
